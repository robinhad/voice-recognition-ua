<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Розпізнавання української мови</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
        integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
</head>

<body>
    <h1>Audio Recording Test</h1>
    <p>Talk for 3 seconds, then you will hear your recording played back</p>
    <button class="btn btn-primary" id="action" onclick="handleAction()">Start recording...</button>
    <div id="result"></div>
    <script src="https://cdn.rawgit.com/mattdiamond/Recorderjs/08e7abd9/dist/recorder.js"></script>
    <script>
        var gumStream; 						//stream from getUserMedia()
        var rec; 							//Recorder.js object
        var input; 							//MediaStreamAudioSourceNode we'll be recording

        // shim for AudioContext when it's not avb. 
        var AudioContext = window.AudioContext || window.webkitAudioContext;
        var audioContext; //audio context to help us record
        var resultNode = document.getElementById('result');

        function resultProcess(data) {
            resultNode.textContent = `Довжина тексту: ${data.length} \n
                Текст: ${data}
            `
        }

        function exportWAV(blob) {
            var data = new FormData()
            data.append('file', blob);
            fetch(`./recognize`, { method: "POST", body: data })
                .then(response => response.text())
                .then(resultProcess);
        }
        function record() {
            var constraints = { audio: true, video: false }
            navigator.mediaDevices.getUserMedia(constraints).then(function (stream) {
                console.log("getUserMedia() success, stream created, initializing Recorder.js ...");

                /*
                    create an audio context after getUserMedia is called
                    sampleRate might change after getUserMedia is called, like it does on macOS when recording through AirPods
                    the sampleRate defaults to the one set in your OS for your playback device
                */
                audioContext = new AudioContext();

                /*  assign to gumStream for later use  */
                gumStream = stream;

                /* use the stream */
                input = audioContext.createMediaStreamSource(stream);

                /* 
                    Create the Recorder object and configure to record mono sound (1 channel)
                    Recording 2 channels  will double the file size
                */
                rec = new Recorder(input, { numChannels: 1 })

                //start the recording process
                rec.record()

                console.log("Recording started");
                sleep(3000).then(stop);
            })
        }


        function stop() {
            rec.stop();

            //stop microphone access
            gumStream.getAudioTracks()[0].stop();

            //create the wav blob and pass it on to createDownloadLink
            rec.exportWAV(exportWAV);
            console.log("Recording stopped")

        }


        const sleep = time => new Promise(resolve => setTimeout(resolve, time));

        async function handleAction() {
            const actionButton = document.getElementById('action');
            actionButton.disabled = true;
            record();
            actionButton.disabled = false;
        }
    </script>
</body>

</html>